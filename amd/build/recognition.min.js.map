{"version":3,"file":"recognition.min.js","sources":["../src/recognition.js"],"sourcesContent":["// This file is part of Moodle - http://moodle.org/\n//\n// Moodle is free software: you can redistribute it and/or modify\n// it under the terms of the GNU General Public License as published by\n// the Free Software Foundation, either version 3 of the License, or\n// (at your option) any later version.\n//\n// Moodle is distributed in the hope that it will be useful,\n// but WITHOUT ANY WARRANTY; without even the implied warranty of\n// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n// GNU General Public License for more details.\n//\n// You should have received a copy of the GNU General Public License\n// along with Moodle.  If not, see <http://www.gnu.org/licenses/>.\n\n/**\n * Javascript to initialise the recognition of a student facial expression.\n *\n * @module     block_emotionanalysis/recognition\n * @copyright  2023 Rohit <rx18008@edu.rta.lv>\n * @license    http://www.gnu.org/copyleft/gpl.html GNU GPL v3 or later\n */\n\n\ndefine(['jquery', 'core/ajax', 'core/url', './youTubeManager', 'core/str'], function($, Ajax, url, youTubeManager, String) {\n    let camArea = document.getElementById(\"live-view\");\n    // eslint-disable-next-line no-unused-vars\n    let modelLoadedStatus = false;\n    let predictedEmotion;\n    let videoElement;\n    let videoWatchTime;\n    let modelsUrl = url.fileUrl('/blocks/emotionanalysis/thirdpartylibs/models', '');\n    Promise.all([\n        // eslint-disable-next-line no-undef\n        faceapi.nets.tinyFaceDetector.loadFromUri(modelsUrl),\n        // eslint-disable-next-line no-undef\n        faceapi.nets.faceLandmark68Net.loadFromUri(modelsUrl),\n        // eslint-disable-next-line no-undef\n        faceapi.nets.faceRecognitionNet.loadFromUri(modelsUrl),\n        // eslint-disable-next-line no-undef\n        faceapi.nets.faceExpressionNet.loadFromUri(modelsUrl),\n        // eslint-disable-next-line no-undef\n        faceapi.nets.ageGenderNet.loadFromUri(modelsUrl),\n        // eslint-disable-next-line no-undef\n        faceapi.nets.ssdMobilenetv1.loadFromUri(modelsUrl),\n        // eslint-disable-next-line promise/always-return\n    ]).then(function() {\n        modelLoadedStatus = true;\n    });\n    const categorizedEmotions = {\n        positive: 0,\n        neutral: 0,\n        negative: 0\n    };\n\n    const happySegment = document.getElementById('happy-segment');\n    const neutralSegment = document.getElementById('neutral-segment');\n    const sadSegment = document.getElementById('sad-segment');\n    happySegment.style.backgroundColor = 'blue';\n    neutralSegment.style.backgroundColor = 'yellow';\n    sadSegment.style.backgroundColor = 'red';\n    const segmentHeight = '20px'; // You can adjust this as needed\n    happySegment.style.height = segmentHeight;\n    neutralSegment.style.height = segmentHeight;\n    sadSegment.style.height = segmentHeight;\n    const transitionDuration = '0.5s'; // You can adjust this as needed\n    happySegment.style.transition = `width ${transitionDuration}`;\n    neutralSegment.style.transition = `width ${transitionDuration}`;\n    sadSegment.style.transition = `width ${transitionDuration}`;\n    // eslint-disable-next-line no-unused-vars\n    let detectionInterval;\n    let element = document.getElementById(\"mod-id\");\n    let value = parseInt(atob(element.getAttribute(\"value\")), 10);\n    if (value === 17) {\n        // Reference the iframe element by its index (you can modify this to match your specific use case)\n        let iframe = document.getElementsByTagName('iframe')[0];\n        if (iframe) {\n            // Set the id attribute for the iframe\n            iframe.setAttribute('id', 'another-love');\n            // Get the current src attribute\n            let currentSrc = iframe.getAttribute('src');\n            // Split the current src at the \"?\" character\n            let srcParts = currentSrc.split('?');\n            // Create the new src with \"?enablejsapi=1\" and the original video ID\n            let newSrc = srcParts[0] + '?enablejsapi=1';\n            // Update the src attribute with the modified URL\n            iframe.setAttribute('src', newSrc);\n        }\n        // eslint-disable-next-line no-undef\n        youTubeManager.readyPromise.then(() => {\n            // eslint-disable-next-line no-unused-vars,no-undef\n            youTubeManager.player.addEventListener('onStateChange', (event) => {\n                // eslint-disable-next-line no-undef\n                if (event.data === YT.PlayerState.PLAYING) {\n                    enableWebCam();\n                    videoWatchTime = youTubeManager.currentTime;\n                    // eslint-disable-next-line no-undef\n                } else if (event.data === 2) {\n                    disableWebCam();\n                }\n            });\n        }).catch(error => {\n            // eslint-disable-next-line no-console\n            console.error(error.message);\n        });\n    } else if (value === 19) {\n        let videoTags = document.getElementsByTagName(\"video\");\n        videoElement = videoTags[1];\n        videoElement.addEventListener(\"play\", () => {\n            videoWatchTime = videoElement.currentTime;\n            enableWebCam();\n        });\n        videoElement.addEventListener(\"pause\", () => {\n            disableWebCam();\n        });\n    }\n    // Returning common variable to use in other modules\n    return {\n        courseId: getDecodedValue(\"course-id-val\"),\n        resourceId: getDecodedValue(\"course-module-id\"),\n        instanceId: getDecodedValue(\"course-instance-id\"),\n        value: value,\n        videoElement: videoElement,\n    };\n    /**\n     * Function to Enable WebCam for emotion Capture\n     */\n    function enableWebCam() {\n        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n            // Not adding audio because we need only video\n            // eslint-disable-next-line promise/always-return\n            navigator.mediaDevices.getUserMedia({video: true}).then(function(stream) {\n                let camArea = document.getElementById(\"live-view\");\n                camArea.srcObject = stream;\n                camArea.play();\n                captureFacialExpression();\n            }).catch(function() {\n                if (value === 19) {\n                    videoElement.pause();\n                    String.get_string('no_camera_permission', 'block_emotionanalysis')\n                        .then(function(text) {\n                            window.alert(text);\n                        });\n                } else if (value === 17) {\n                    youTubeManager.player.pauseVideo(); // Pause the YouTube video\n                    youTubeManager.player.addEventListener('onStateChange', function(event) {\n                        // eslint-disable-next-line no-undef\n                        if (event.data === YT.PlayerState.PAUSED) {\n                            String.get_string('no_camera_permission', 'block_emotionanalysis')\n                                .then(function(text) {\n                                    window.alert(text);\n                                });\n                            camArea.srcObject = null;\n                        }\n                    });\n                }\n            });\n        }\n    }\n\n    /**\n     * Function to disable WebCam\n     */\n    function disableWebCam() {\n        camArea.srcObject = null;\n        clearInterval(detectionInterval);\n    }\n\n    /**\n     * function to capture Facial Expression\n     */\n    function captureFacialExpression() {\n        let noFaceFound;\n        let prevEmotionState;\n        detectionInterval = setInterval(async() =>{\n            // eslint-disable-next-line no-undef\n            let detections = await faceapi.detectAllFaces(camArea,\n                // eslint-disable-next-line no-undef\n                new faceapi.TinyFaceDetectorOptions({scoreThreshold: 0.3,\n                    inputsize: 320})).withFaceExpressions().withAgeAndGender();\n            if (detections.length === 0) {\n                // eslint-disable-next-line no-undef,max-len\n                detections = await faceapi.detectAllFaces(camArea,\n                    // eslint-disable-next-line no-undef\n                    new faceapi.SsdMobilenetv1Options({scoreThreshold: 0.3,\n                        inputsize: 320})).withFaceExpressions().withAgeAndGender();\n            }\n            if (detections.length > 0) {\n                let gender = detections[0].gender;\n                let ageGroup = detections[0].age;\n                const result = getVideoTimeStamp(value);\n                // Sorting the array\n                predictedEmotion = Object.fromEntries(Object.entries(detections[0].expressions).sort(([, a], [, b]) => b - a));\n                let emotionState = Object.keys(predictedEmotion)[0];\n                let secondEmotion = Object.keys(predictedEmotion)[1];\n                if (emotionState === 'happy'\n                    || (emotionState === 'surprised' && secondEmotion === 'happy')\n                    || (emotionState === 'neutral' && secondEmotion === 'happy')) {\n                    categorizedEmotions.positive++;\n                } else if (emotionState === 'neutral') {\n                    categorizedEmotions.neutral++;\n                } else {\n                    categorizedEmotions.negative++;\n                }\n                // eslint-disable-next-line no-unused-vars\n                let totalEmotion = Object.values(categorizedEmotions).reduce((acc, value) => acc + value, 0);\n                requestAnimationFrame(() => updateEmotionBar(totalEmotion));\n                if (emotionState !== prevEmotionState) {\n                    let requestData = {\n                        \"values\": {\n                            \"emotionState\": emotionState,\n                            \"videoTimeStamp\": Math.floor(result.currentTime),\n                            \"courseId\": getDecodedValue(\"course-id-val\"),\n                            \"resourceId\": getDecodedValue(\"course-module-id\"),\n                            \"instanceId\": getDecodedValue(\"course-instance-id\"),\n                            \"totalDuration\": Math.floor(result.totalDuration),\n                            \"videoWatchTime\": Math.floor(videoWatchTime),\n                            \"gender\": gender,\n                            \"ageGroup\": ageGroup,\n                        }\n                    };\n                    prevEmotionState = emotionState;\n                    let request = {\n                        methodname: 'blocks_emotionanalysis_capture_emotions',\n                        args: requestData\n                    };\n                    Ajax.call([request])[0].done(function(data) {\n                        // eslint-disable-next-line no-console\n                        console.log(data);\n                    }).fail(function(data) {\n                        // eslint-disable-next-line no-console\n                        console.log(data.error);\n                    });\n                    noFaceFound = 0;\n                }\n            } else {\n                // eslint-disable-next-line no-console\n                console.log(\"No face Found\");\n                noFaceFound = ++noFaceFound;\n                if (noFaceFound > 10) {\n                    if (value === 19)\n                    {\n                        videoElement.pause();\n                        window.alert(\"we are unable to find any face Please adjust your camera or Position\");\n                    } else {\n                        youTubeManager.player.pauseVideo(); // Pause the YouTube video\n                        youTubeManager.player.addEventListener('onStateChange', function(event) {\n                            // eslint-disable-next-line no-undef\n                            if (event.data === YT.PlayerState.PAUSED) {\n                                // The YouTube video has been paused, continue with other code.\n                                window.alert(\"We are unable to find any face. Please adjust your camera or position.\");\n                                camArea.srcObject = null;\n                            }\n                        });\n                    }\n                    clearInterval(detectionInterval);\n                    camArea.srcObject = null;\n                    noFaceFound = 0;\n                }\n            }\n        }, 1000);\n    }\n    /**\n     * Javascript to getDecodedValue.\n     * @param {string} id getting the id of the current block\n     * @return {string}\n     */\n    function getDecodedValue(id) {\n        let element = document.getElementById(id);\n        // Return the decoded value\n        return atob(element.getAttribute(\"value\"));\n    }\n\n    /**\n     * Function get Video Timestamp\n     *@param {int} moduleType\n     * @return {int} currentTime\n     * @return {int} totalDuration\n     */\n    function getVideoTimeStamp(moduleType) {\n        if (moduleType === 17) {\n            return {\n                currentTime: youTubeManager.player.getCurrentTime(),\n                totalDuration: youTubeManager.player.getDuration()\n            };\n        } else if (moduleType === 19) {\n            return {\n                currentTime: videoElement.currentTime,\n                totalDuration: videoElement.duration\n            };\n        }\n    }\n    /**\n     *Function to update emotion bar\n     * @param {int} totalEmotion number of total collected values\n     */\n    function updateEmotionBar(totalEmotion) {\n        const happySegment = document.getElementById('happy-segment');\n        const neutralSegment = document.getElementById('neutral-segment');\n        const sadSegment = document.getElementById('sad-segment');\n\n        // eslint-disable-next-line no-undef\n        happySegment.style.width = `${(categorizedEmotions.positive / totalEmotion) * 100}%`;\n        // eslint-disable-next-line no-undef\n        neutralSegment.style.width = `${(categorizedEmotions.neutral / totalEmotion) * 100}%`;\n        // eslint-disable-next-line no-undef\n        sadSegment.style.width = `${(categorizedEmotions.negative / totalEmotion) * 100}%`;\n    }\n});"],"names":["define","$","Ajax","url","youTubeManager","String","predictedEmotion","videoElement","videoWatchTime","camArea","document","getElementById","modelLoadedStatus","modelsUrl","fileUrl","Promise","all","faceapi","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","ssdMobilenetv1","then","categorizedEmotions","positive","neutral","negative","happySegment","neutralSegment","sadSegment","style","backgroundColor","height","detectionInterval","transition","element","value","parseInt","atob","getAttribute","iframe","getElementsByTagName","setAttribute","newSrc","split","readyPromise","player","addEventListener","event","data","YT","PlayerState","PLAYING","enableWebCam","currentTime","disableWebCam","catch","error","console","message","videoTags","courseId","getDecodedValue","resourceId","instanceId","navigator","mediaDevices","getUserMedia","video","stream","srcObject","play","captureFacialExpression","pause","get_string","text","window","alert","pauseVideo","PAUSED","clearInterval","noFaceFound","prevEmotionState","setInterval","async","detections","detectAllFaces","TinyFaceDetectorOptions","scoreThreshold","inputsize","withFaceExpressions","withAgeAndGender","length","SsdMobilenetv1Options","gender","ageGroup","age","result","moduleType","getCurrentTime","totalDuration","getDuration","duration","getVideoTimeStamp","Object","fromEntries","entries","expressions","sort","a","b","emotionState","keys","secondEmotion","totalEmotion","values","reduce","acc","requestAnimationFrame","width","updateEmotionBar","requestData","Math","floor","request","methodname","args","call","done","log","fail","id"],"mappings":";;;;;;;AAwBAA,2CAAO,CAAC,SAAU,YAAa,WAAY,mBAAoB,aAAa,SAASC,EAAGC,KAAMC,IAAKC,eAAgBC,YAI3GC,iBACAC,aACAC,eALAC,QAAUC,SAASC,eAAe,aAElCC,mBAAoB,EAIpBC,UAAYV,IAAIW,QAAQ,gDAAiD,IAC7EC,QAAQC,IAAI,CAERC,QAAQC,KAAKC,iBAAiBC,YAAYP,WAE1CI,QAAQC,KAAKG,kBAAkBD,YAAYP,WAE3CI,QAAQC,KAAKI,mBAAmBF,YAAYP,WAE5CI,QAAQC,KAAKK,kBAAkBH,YAAYP,WAE3CI,QAAQC,KAAKM,aAAaJ,YAAYP,WAEtCI,QAAQC,KAAKO,eAAeL,YAAYP,aAEzCa,MAAK,WACJd,mBAAoB,WAElBe,oBAAsB,CACxBC,SAAU,EACVC,QAAS,EACTC,SAAU,GAGRC,aAAerB,SAASC,eAAe,iBACvCqB,eAAiBtB,SAASC,eAAe,mBACzCsB,WAAavB,SAASC,eAAe,eAC3CoB,aAAaG,MAAMC,gBAAkB,OACrCH,eAAeE,MAAMC,gBAAkB,SACvCF,WAAWC,MAAMC,gBAAkB,MAEnCJ,aAAaG,MAAME,OADG,OAEtBJ,eAAeE,MAAME,OAFC,OAGtBH,WAAWC,MAAME,OAHK,WASlBC,kBAJJN,aAAaG,MAAMI,2BADQ,QAE3BN,eAAeE,MAAMI,2BAFM,QAG3BL,WAAWC,MAAMI,2BAHU,YAMvBC,QAAU7B,SAASC,eAAe,UAClC6B,MAAQC,SAASC,KAAKH,QAAQI,aAAa,UAAW,OAC5C,KAAVH,MAAc,KAEVI,OAASlC,SAASmC,qBAAqB,UAAU,MACjDD,OAAQ,CAERA,OAAOE,aAAa,KAAM,oBAMtBC,OAJaH,OAAOD,aAAa,OAEXK,MAAM,KAEV,GAAK,iBAE3BJ,OAAOE,aAAa,MAAOC,QAG/B3C,eAAe6C,aAAavB,MAAK,KAE7BtB,eAAe8C,OAAOC,iBAAiB,iBAAkBC,QAEjDA,MAAMC,OAASC,GAAGC,YAAYC,SAC9BC,eACAjD,eAAiBJ,eAAesD,aAEV,IAAfN,MAAMC,MACbM,sBAGTC,OAAMC,QAELC,QAAQD,MAAMA,MAAME,iBAErB,GAAc,KAAVvB,MAAc,KACjBwB,UAAYtD,SAASmC,qBAAqB,SAC9CtC,aAAeyD,UAAU,GACzBzD,aAAa4C,iBAAiB,QAAQ,KAClC3C,eAAiBD,aAAamD,YAC9BD,kBAEJlD,aAAa4C,iBAAiB,SAAS,KACnCQ,yBAID,CACHM,SAAUC,gBAAgB,iBAC1BC,WAAYD,gBAAgB,oBAC5BE,WAAYF,gBAAgB,sBAC5B1B,MAAOA,MACPjC,aAAcA,uBAKTkD,eACDY,UAAUC,cAAgBD,UAAUC,aAAaC,cAGjDF,UAAUC,aAAaC,aAAa,CAACC,OAAO,IAAO9C,MAAK,SAAS+C,YACzDhE,QAAUC,SAASC,eAAe,aACtCF,QAAQiE,UAAYD,OACpBhE,QAAQkE,OACRC,6BACDhB,OAAM,WACS,KAAVpB,OACAjC,aAAasE,QACbxE,OAAOyE,WAAW,uBAAwB,yBACrCpD,MAAK,SAASqD,MACXC,OAAOC,MAAMF,UAEJ,KAAVvC,QACPpC,eAAe8C,OAAOgC,aACtB9E,eAAe8C,OAAOC,iBAAiB,iBAAiB,SAASC,OAEzDA,MAAMC,OAASC,GAAGC,YAAY4B,SAC9B9E,OAAOyE,WAAW,uBAAwB,yBACrCpD,MAAK,SAASqD,MACXC,OAAOC,MAAMF,SAErBtE,QAAQiE,UAAY,sBAWnCf,gBACLlD,QAAQiE,UAAY,KACpBU,cAAc/C,4BAMTuC,8BACDS,YACAC,iBACJjD,kBAAoBkD,aAAYC,cAExBC,iBAAmBxE,QAAQyE,eAAejF,QAE1C,IAAIQ,QAAQ0E,wBAAwB,CAACC,eAAgB,GACjDC,UAAW,OAAOC,sBAAsBC,sBACtB,IAAtBN,WAAWO,SAEXP,iBAAmBxE,QAAQyE,eAAejF,QAEtC,IAAIQ,QAAQgF,sBAAsB,CAACL,eAAgB,GAC/CC,UAAW,OAAOC,sBAAsBC,oBAEhDN,WAAWO,OAAS,EAAG,KACnBE,OAAST,WAAW,GAAGS,OACvBC,SAAWV,WAAW,GAAGW,UACvBC,gBAyFSC,eACJ,KAAfA,iBACO,CACH5C,YAAatD,eAAe8C,OAAOqD,iBACnCC,cAAepG,eAAe8C,OAAOuD,eAEtC,GAAmB,KAAfH,iBACA,CACH5C,YAAanD,aAAamD,YAC1B8C,cAAejG,aAAamG,UAlGbC,CAAkBnE,OAEjClC,iBAAmBsG,OAAOC,YAAYD,OAAOE,QAAQrB,WAAW,GAAGsB,aAAaC,MAAK,oBAAIC,UAAOC,gBAAOA,EAAID,UACvGE,aAAeP,OAAOQ,KAAK9G,kBAAkB,GAC7C+G,cAAgBT,OAAOQ,KAAK9G,kBAAkB,GAC7B,UAAjB6G,cACqB,cAAjBA,cAAkD,UAAlBE,eACf,YAAjBF,cAAgD,UAAlBE,cAClC1F,oBAAoBC,WACI,YAAjBuF,aACPxF,oBAAoBE,UAEpBF,oBAAoBG,eAGpBwF,aAAeV,OAAOW,OAAO5F,qBAAqB6F,QAAO,CAACC,IAAKjF,QAAUiF,IAAMjF,OAAO,MAC1FkF,uBAAsB,aA0FRJ,oBAChBvF,aAAerB,SAASC,eAAe,iBACvCqB,eAAiBtB,SAASC,eAAe,mBACzCsB,WAAavB,SAASC,eAAe,eAG3CoB,aAAaG,MAAMyF,gBAAYhG,oBAAoBC,SAAW0F,aAAgB,SAE9EtF,eAAeE,MAAMyF,gBAAYhG,oBAAoBE,QAAUyF,aAAgB,SAE/ErF,WAAWC,MAAMyF,gBAAYhG,oBAAoBG,SAAWwF,aAAgB,SApGxCM,CAAiBN,gBACzCH,eAAiB7B,iBAAkB,KAC/BuC,YAAc,QACJ,cACUV,4BACEW,KAAKC,MAAM1B,OAAO3C,sBACxBQ,gBAAgB,4BACdA,gBAAgB,+BAChBA,gBAAgB,oCACb4D,KAAKC,MAAM1B,OAAOG,8BACjBsB,KAAKC,MAAMvH,uBACnB0F,gBACEC,WAGpBb,iBAAmB6B,iBACfa,QAAU,CACVC,WAAY,0CACZC,KAAML,aAEV3H,KAAKiI,KAAK,CAACH,UAAU,GAAGI,MAAK,SAAS/E,MAElCS,QAAQuE,IAAIhF,SACbiF,MAAK,SAASjF,MAEbS,QAAQuE,IAAIhF,KAAKQ,UAErBwB,YAAc,QAIlBvB,QAAQuE,IAAI,iBACZhD,cAAgBA,YACZA,YAAc,KACA,KAAV7C,OAEAjC,aAAasE,QACbG,OAAOC,MAAM,0EAEb7E,eAAe8C,OAAOgC,aACtB9E,eAAe8C,OAAOC,iBAAiB,iBAAiB,SAASC,OAEzDA,MAAMC,OAASC,GAAGC,YAAY4B,SAE9BH,OAAOC,MAAM,0EACbxE,QAAQiE,UAAY,UAIhCU,cAAc/C,mBACd5B,QAAQiE,UAAY,KACpBW,YAAc,KAGvB,cAOEnB,gBAAgBqE,QACjBhG,QAAU7B,SAASC,eAAe4H,WAE/B7F,KAAKH,QAAQI,aAAa"}